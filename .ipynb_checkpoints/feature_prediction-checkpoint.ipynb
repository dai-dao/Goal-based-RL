{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Reference](https://www.oreilly.com/ideas/reinforcement-learning-for-complex-goals-using-tensorflow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from gridworld_goals import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ExperienceBuffer():\n",
    "    def __init__(self, buffer_size = 50000):\n",
    "        self.buffer = []\n",
    "        self.buffer_size = buffer_size\n",
    "    \n",
    "    def add(self, experience):\n",
    "        if len(list(self.buffer)) + len(list(experience)) >= self.buffer_size:\n",
    "            self.buffer[0:(len(list(experience))+len(list(self.buffer)))-self.buffer_size] = []\n",
    "        self.buffer.extend(zip(experience))\n",
    "            \n",
    "    def sample(self,size):\n",
    "        return np.reshape(np.array(random.sample(self.buffer, size)), [size, 5])\n",
    "    \n",
    "def get_f(m, offsets):\n",
    "    f = np.zeros([len(m), m.shape[1], len(offsets)])\n",
    "    for i, offset in enumerate(offsets):\n",
    "        f[:-offset, :, i] = m[offset:, :] - m[:-offset, :]\n",
    "        if i > 0:\n",
    "            f[-offset:, :, i] = f[-offset:, :, i-1]\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DFP(nn.Module):\n",
    "    def __init__(self, action_size, observation_shape, num_measurements, num_offsets):\n",
    "        super(DFP, self).__init__()\n",
    "        \n",
    "        self.observation_shape = observation_shape\n",
    "        self.num_measurements = num_measurements\n",
    "        self.action_size = action_size\n",
    "        self.num_goals = num_measurements\n",
    "        self.num_offsets = num_offsets\n",
    "        \n",
    "        self.h_o = nn.Linear(int(np.prod(observation_shape)), 128)\n",
    "        self.h_m = nn.Linear(num_measurements, 64)\n",
    "        self.h_g = nn.Linear(num_measurements, 64)\n",
    "        self.h = nn.Linear(128 + 64 + 64, 256)\n",
    "        \n",
    "        # Calculate separate expectations and advantage stream\n",
    "        self.h_expectation = nn.Linear(256, action_size * self.num_offsets * self.num_measurements)\n",
    "        self.h_advantages = nn.Linear(256, action_size * self.num_offsets * self.num_measurements)\n",
    "        \n",
    "        \n",
    "    def forward(self, observation, measurement, goals, temp):\n",
    "        observation_flatten = observation.view(observation.size()[0], -1)\n",
    "        h_o = F.elu(self.h_o(observation_flatten))\n",
    "        h_m = F.elu(self.h_m(measurement))\n",
    "        h_g = F.elu(self.h_g(goals))\n",
    "        \n",
    "        h = torch.cat([h_o, h_m, h_g], dim=1)\n",
    "        h_ = F.elu(self.h(h))\n",
    "        \n",
    "        expectations = self.h_expectation(h_)\n",
    "        advantages = self.h_advantages(h_)\n",
    "        advantages = advantages - advantages.mean(1).expand_as(advantages)\n",
    "        \n",
    "        predictions = expectations + advantages\n",
    "        predictions = predictions.view(-1, self.num_measurements, self.action_size, self.num_offsets)\n",
    "        \n",
    "        boltzman = F.softmax(predictions.mean(3) / temp)\n",
    "        boltzman = boltzman.squeeze(3)\n",
    "        return boltzman, predictions\n",
    "    \n",
    "    def compute_loss(self, observation, measurement, goals, temp, action, target):\n",
    "        boltzman, predictions = self(observation, measurement, goals, temp)\n",
    "        pred_action = (predictions * action_onehot.view(-1, 1, self.action_size, 1)).sum(2)\n",
    "        \n",
    "        loss = nn.MSE(pred_action, target)\n",
    "        entropy = -(boltzman * torch.log(boltzman + 1e-7)).sum()\n",
    "        total_loss = loss + entropy\n",
    "        \n",
    "        # Backward and optimize step\n",
    "        '''\n",
    "        optimizer.zero_grad()\n",
    "        total_loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm(self.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        \n",
    "        '''\n",
    "        \n",
    "        return loss, entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a_size = 4 # Number of available actions\n",
    "num_measurements = 2\n",
    "learning_rate = 1e-3 \n",
    "num_episodes = 130\n",
    "offsets = [1, 2, 4, 8, 16, 32] # Set of temporal offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Trainer():\n",
    "    def __init__(self):\n",
    "        self.exp_buff = ExperienceBuffer()\n",
    "        self.env = gameEnv(partial=False, size=5)\n",
    "        s, o_big, m, g, h = self.env.reset()\n",
    "        self.model = DFP(a_size, s.shape, num_measurements, len(offsets))\n",
    "\n",
    "    def work(self):\n",
    "        episode_deliveries = []\n",
    "        episode_lengths = []\n",
    "\n",
    "        for _ in range(num_episodes):\n",
    "            episode_buffer = []\n",
    "            episode_frames = []\n",
    "            d = False\n",
    "            t = 0\n",
    "            temp = 0.25 #How spread out we want our action distribution to be\n",
    "\n",
    "            s, o_big, m, g, h = self.env.reset()\n",
    "            current_goal = None\n",
    "\n",
    "            while d is False:\n",
    "                if m[1] <= .3:\n",
    "                    current_goal = np.array([0.0,1.0])\n",
    "                else:\n",
    "                    current_goal = np.array([1.0,0.0])\n",
    "\n",
    "                # Convert to Variable\n",
    "                m = np.array(m)\n",
    "                s_var = Variable(torch.from_numpy(s)).float().unsqueeze(0)\n",
    "                m_var = Variable(torch.from_numpy(m)).float().unsqueeze(0)\n",
    "                g_var = Variable(torch.from_numpy(current_goal)).float().unsqueeze(0)\n",
    "\n",
    "                # Compute action probabilities\n",
    "                boltzman, _ = self.model(s_var, m_var, g_var, temp)\n",
    "                b = current_goal * boltzman.data.numpy()[0].T\n",
    "                c = np.sum(b,1)\n",
    "                c /= c.sum()\n",
    "                a = np.random.choice(c, p=c)\n",
    "                a = np.argmax(c == a)\n",
    "\n",
    "                # Add to episode buffer\n",
    "                episode_buffer.append([s, a, m, current_goal, np.zeros(len(offsets))])\n",
    "\n",
    "                # Perform the action on the environment\n",
    "                s, s1_big, m, g, h, d = self.env.step(a) \n",
    "                t += 1\n",
    "\n",
    "                # End the episode after 100 steps\n",
    "                if t > 100:\n",
    "                    d = True\n",
    "\n",
    "            # Training statistics\n",
    "            episode_deliveries.append(m[0])\n",
    "            episode_lengths.append(t)\n",
    "\n",
    "            # Update the network using experience buffer at the end\n",
    "            # of the episode\n",
    "            self.train(episode_buffer)    \n",
    "\n",
    "    def train(self, rollout):\n",
    "        rollout = np.array(rollout)\n",
    "        measurements = np.vstack(rollout[:,2])\n",
    "        targets = get_f(measurements, offsets)\n",
    "        rollout[:,4] = zip(targets)\n",
    "        self.exp_buff.add(rollout)\n",
    "        \n",
    "        print('check target shape', targets.shape)\n",
    "        \n",
    "        # Get a batch of experiences from the buffer and \n",
    "        # use them to update the global network\n",
    "        if len(self.exp_buff.buffer) > 128:\n",
    "            exp_batch = self.exp_buff.sample(128)\n",
    "\n",
    "            observation_batch = np.stack(exp_batch[:, 0], axis=0)\n",
    "            measurement_batch = np.vstack(exp_batch[:, 2])\n",
    "            temperature = 0.1\n",
    "            action_batch = exp_batch[:, 1]\n",
    "            target_batch_zip = np.vstack(exp_batch[:, 4])\n",
    "            target_batch = []\n",
    "            \n",
    "            for z in target_batch_zip:\n",
    "                arr = np.array([*z[0]])\n",
    "                target_batch.append(arr)\n",
    "            \n",
    "            target_batch = np.array(target_batch)\n",
    "            print(target_batch[110].shape)\n",
    "            \n",
    "            #target_batch = np.vstack([*exp_batch[:, 4]])\n",
    "            goal_batch = np.vstack(exp_batch[:, 3])\n",
    "\n",
    "            # Convert to variables\n",
    "            obs_var = Variable(torch.from_numpy(observation_batch)).float()\n",
    "            mea_var = Variable(torch.from_numpy(measurement_batch)).float()\n",
    "            goa_var = Variable(torch.from_numpy(goal_batch)).float()\n",
    "            act_var = Variable(torch.from_numpy(action_batch.astype(np.int32))).float()\n",
    "            tar_var = Variable(torch.from_numpy(target_batch.astype(np.float32))).float()\n",
    "            \n",
    "            loss, entropy = self.model.compute_loss(obs_var, mea_var,\n",
    "                                                    goa_var, temperature, \n",
    "                                                    act_var, tar_var)\n",
    "            return loss / len(rollout), entropy / len(rollout)\n",
    "        else:\n",
    "            return 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check target shape (43, 2, 6)\n",
      "check target shape (80, 2, 6)\n",
      "check target shape (40, 2, 6)\n",
      "(0,)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-125-a37c5c9a8c9e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-124-4a68124d6ba2>\u001b[0m in \u001b[0;36mwork\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;31m# Update the network using experience buffer at the end\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0;31m# of the episode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepisode_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrollout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-124-4a68124d6ba2>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, rollout)\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0mgoa_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgoal_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0mact_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m             \u001b[0mtar_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m             loss, entropy = self.model.compute_loss(obs_var, mea_var,\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "trainer = Trainer()\n",
    "trainer.work()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
